# ================== Q-ProVe-Phish (PROPOSED) + Baselines — Full Evaluation Suite (Terra-only default) ==================
# - Default: Terra-only statevector kernels (no Aer, no qiskit-ml)
# - Optional toggles: USE_AER, USE_QML (auto-fallback if not available)
# - Dataset: UCI Website Phishing (ARFF-in-ZIP)
# - Outputs saved to: ./qcar_qiskit_outputs_final/
# - Evaluation artifacts:
#     * leaderboard_all_metrics_UPDATED.csv
#     * evaluation_dashboard_UPDATED.png  (ROC/PR overlays + bar charts)
#     * diagnostics_dashboard_UPDATED.png (Calibration, DET, Decision curves)
#     * policy_dashboard_UPDATED.png      (Gains, Lift, Threshold sweeps)
#     * confusion_matrices_UPDATED.png/.csv (all models in one figure + raw counts)

import sys, subprocess, importlib, os, io, zipfile, urllib.request, warnings, math, random
warnings.filterwarnings("ignore")

# -------------------------- CONFIG --------------------------
OUT_DIR = "qcar_qiskit_outputs_final"; os.makedirs(OUT_DIR, exist_ok=True)
SEED = 42
np_random = random.Random(SEED)

# Quantum / model limits
N_QUBITS = 8              # PCA -> #qubits
ALPHA = 0.10              # conformal gate tail
Q_TRAIN_MAX = 600         # cap QSVC training set
QKS_SINKS = 8             # QKS sinks
QKS_R1, QKS_R2 = 1, 2

# Optional stacks (default is Terra-only)
USE_AER  = True        # if True and qiskit_aer is present, can use Aer statevector
USE_QML  = True          # if True and qiskit-machine-learning (+ possibly primitives) are present, can use ML kernels
# ------------------------------------------------------------

# Lightweight installs only for the essentials (no heavy auto-installs by default)
def ensure(pkg):
    try: importlib.import_module(pkg)
    except Exception:
        print(f"[setup] Installing {pkg} ...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", pkg])

for pkg in ["numpy", "pandas", "scipy", "scikit-learn", "matplotlib", "qiskit"]:
    ensure(pkg)

import numpy as np, pandas as pd
from scipy.io import arff

from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    average_precision_score, confusion_matrix, log_loss, balanced_accuracy_score,
    cohen_kappa_score, matthews_corrcoef, roc_curve, precision_recall_curve, brier_score_loss
)
from sklearn.calibration import calibration_curve

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib import gridspec

# Qiskit Terra (core)
from qiskit.circuit import QuantumCircuit
from qiskit.quantum_info import Statevector

# Optional: Aer / qiskit-ml (only used if flags True and imports succeed)
HAS_AER = False
HAS_QML = False
HAS_PRIMITIVES = False
if USE_AER:
    try:
        import qiskit_aer
        HAS_AER = True
        from qiskit_aer import Aer
    except Exception:
        print("[warn] qiskit_aer not available; staying Terra-only.")
if USE_QML:
    try:
        import qiskit_machine_learning
        HAS_QML = True
        try:
            from qiskit_machine_learning.kernels import QuantumKernel, FidelityQuantumKernel
        except Exception:
            # older/newer API fallback
            from qiskit_machine_learning.kernels.quantum_kernel import QuantumKernel
            from qiskit_machine_learning.kernels.fidelity_quantum_kernel import FidelityQuantumKernel
        try:
            from qiskit.primitives import Sampler
            from qiskit_algorithms.state_fidelities import ComputeUncompute
            HAS_PRIMITIVES = True
        except Exception:
            HAS_PRIMITIVES = False
    except Exception:
        print("[warn] qiskit-machine-learning not available; staying Terra-only.")
        HAS_QML = False
        HAS_PRIMITIVES = False

# -------------------------- Data --------------------------
DATA_URL = "https://archive.ics.uci.edu/static/public/379/website%2Bphishing.zip"

def dl_and_read_arffs(url: str) -> pd.DataFrame:
    zpath = os.path.join(OUT_DIR, "website_phishing.zip")
    if not os.path.exists(zpath):
        print(f"[data] Downloading {url}")
        urllib.request.urlretrieve(url, zpath)
    frames = []
    with zipfile.ZipFile(zpath, "r") as zf:
        names = [n for n in zf.namelist() if n.lower().endswith(".arff")]
        if not names: raise RuntimeError("No .arff files in ZIP.")
        for name in names:
            with zf.open(name, "r") as raw:
                with io.TextIOWrapper(raw, encoding="utf-8", errors="ignore", newline="") as tf:
                    data, meta = arff.loadarff(tf)
            df = pd.DataFrame(data)
            for c in df.columns:
                if df[c].dtype == object and len(df[c]):
                    v = df[c].iloc[0]
                    if isinstance(v, (bytes, bytearray)):
                        df[c] = df[c].apply(lambda x: x.decode("utf-8","ignore") if isinstance(x,(bytes,bytearray)) else x)
            frames.append(df)
    return pd.concat(frames, axis=0, ignore_index=True)

def find_label_column(df: pd.DataFrame) -> str:
    for c in ["Result","result","Class","class","Label","label","Target","target"]:
        if c in df.columns: return c
    return df.columns[-1]

df = dl_and_read_arffs(DATA_URL)
label_col = find_label_column(df)

def to_binary_label(s):
    try:
        return 1 if float(s) > 0 else 0
    except:
        return 1 if str(s).strip().lower() in ("1","legitimate","benign","true","yes") else 0

y = df[label_col].apply(to_binary_label).astype(int).values
X = df.drop(columns=[label_col]).copy()
for c in X.columns:
    X[c] = pd.to_numeric(X[c], errors="coerce")
X = X.fillna(0)

# 60/20/20 split
X_trv, X_te, y_trv, y_te = train_test_split(X, y, test_size=0.20, random_state=SEED, stratify=y)
X_tr,  X_ca, y_tr,  y_ca = train_test_split(X_trv, y_trv, test_size=0.25, random_state=SEED, stratify=y_trv)

# -------------------------- Preprocessing --------------------------
std = StandardScaler()
Xtr_s = std.fit_transform(X_tr)
Xca_s = std.transform(X_ca)
Xte_s = std.transform(X_te)

pca = PCA(n_components=N_QUBITS, random_state=SEED)
Xtr_p = pca.fit_transform(Xtr_s)
Xca_p = pca.transform(Xca_s)
Xte_p = pca.transform(Xte_s)

mins = Xtr_p.min(axis=0, keepdims=True)
maxs = Xtr_p.max(axis=0, keepdims=True)
rng  = np.where((maxs - mins) == 0, 1.0, (maxs - mins))
to_theta = lambda Z: (Z - mins)/rng * (2*np.pi)
Xtr_th, Xca_th, Xte_th = map(to_theta, [Xtr_p, Xca_p, Xte_p])

# -------------------------- Utility / Metrics --------------------------
def clamp_proba(p, eps=1e-9):
    p = np.asarray(p, float)
    if p.ndim == 1:
        p = np.clip(p, eps, 1-eps); return np.c_[1-p, p]
    p = np.clip(p, eps, 1-eps); p = p / p.sum(axis=1, keepdims=True); return p

def specificity_tnr(y_true, yhat):
    tn, fp, fn, tp = confusion_matrix(y_true, yhat, labels=[0,1]).ravel()
    return tn / max(1, (tn + fp))

def all_metrics(y_true, proba, yhat=None):
    proba = clamp_proba(proba)
    if yhat is None: yhat = (proba[:,1] >= 0.5).astype(int)
    return dict(
        Accuracy        = accuracy_score(y_true, yhat),
        Precision       = precision_score(y_true, yhat, zero_division=0),
        Recall          = recall_score(y_true, yhat, zero_division=0),
        F1              = f1_score(y_true, yhat, zero_division=0),
        ROC_AUC         = roc_auc_score(y_true, proba[:,1]) if len(np.unique(y_true))>1 else np.nan,
        PR_AUC          = average_precision_score(y_true, proba[:,1]),
        Log_Loss        = log_loss(y_true, proba, labels=[0,1]),
        Balanced_Acc    = balanced_accuracy_score(y_true, yhat),
        Specificity_TNR = specificity_tnr(y_true, yhat),
        Cohen_Kappa     = cohen_kappa_score(y_true, yhat),
        MCC             = matthews_corrcoef(y_true, yhat),
        Brier_Score     = brier_score_loss(y_true, proba[:,1]),
    )

# -------------------------- Classical base + gate --------------------------
cl_lr = LogisticRegression(max_iter=1000, random_state=SEED).fit(Xtr_s, y_tr)
p_tr_c = clamp_proba(cl_lr.predict_proba(Xtr_s))
p_ca_c = clamp_proba(cl_lr.predict_proba(Xca_s))
p_te_c = clamp_proba(cl_lr.predict_proba(Xte_s))

def nonconformity(p):
    return 1.0 - np.max(p, axis=1)

scores_ca = nonconformity(p_ca_c)
try: qhat = np.quantile(scores_ca, 1-ALPHA, method="higher")
except TypeError: qhat = np.quantile(scores_ca, 1-ALPHA)

scores_te = nonconformity(p_te_c)
route_mask = ~(scores_te <= qhat)

# -------------------------- Terra feature map / fidelity kernel --------------------------
def build_state(angles, reps=1, ent="linear", pairs=None):
    qc = QuantumCircuit(N_QUBITS)
    for _ in range(reps):
        for i in range(N_QUBITS):
            qc.ry(float(angles[i]), i)
        if ent == "linear":
            for i in range(N_QUBITS-1):
                qc.cx(i, i+1)
        elif ent == "ring":
            for i in range(N_QUBITS):
                qc.cx(i, (i+1) % N_QUBITS)
        elif ent == "random":
            pp = pairs
            if pp is None:
                perm = np.random.permutation(N_QUBITS)
                pp = list(zip(perm[:-1], perm[1:]))
            for a,b in pp:
                if a!=b: qc.cx(int(a), int(b))
    # Terra-only exact statevector
    return Statevector.from_instruction(qc).data

def sv_matrix(Xtheta, reps=1, ent="linear", pairs=None, use_aer=False):
    if not use_aer:
        return np.stack([build_state(x, reps=reps, ent=ent, pairs=pairs) for x in Xtheta], axis=0)
    # Aer statevector path (optional)
    backend = Aer.get_backend("statevector_simulator")
    vecs = []
    for x in Xtheta:
        qc = QuantumCircuit(N_QUBITS)
        for _ in range(reps):
            for i in range(N_QUBITS): qc.ry(float(x[i]), i)
            if ent == "linear":
                for i in range(N_QUBITS-1): qc.cx(i, i+1)
            elif ent == "ring":
                for i in range(N_QUBITS): qc.cx(i, (i+1) % N_QUBITS)
            elif ent == "random":
                pp = pairs
                if pp is None:
                    perm = np.random.permutation(N_QUBITS)
                    pp = list(zip(perm[:-1], perm[1:]))
                for a,b in pp:
                    if a!=b: qc.cx(int(a), int(b))
        job = backend.run(qc)
        sv = job.result().get_statevector(qc)
        vecs.append(sv.data if hasattr(sv, "data") else sv)
    return np.stack(vecs, axis=0)

def fidelity_kernel(SA, SB):
    # K = |SA @ SB^H|^2
    K = SA @ SB.conj().T
    return np.abs(K)**2

def strat_cap_idx(y_arr, max_n, seed=SEED):
    if len(y_arr) <= max_n: return np.arange(len(y_arr))
    sss = StratifiedShuffleSplit(n_splits=1, train_size=max_n, random_state=seed)
    idx = np.arange(len(y_arr)); tr, _ = next(sss.split(idx, y_arr)); return tr

# -------------------------- QSVC Experts (r=1,2) --------------------------
from sklearn.svm import SVC

tr_cap = strat_cap_idx(y_tr, Q_TRAIN_MAX, seed=SEED)
Xtr_th_q, ytr_q = Xtr_th[tr_cap], y_tr[tr_cap]

def qsvc_probs(Xtr_th_q, ytr_q, Xte_th, reps=1, ent="linear", pairs=None):
    use_aer_flag = HAS_AER and USE_AER
    SA = sv_matrix(Xtr_th_q, reps=reps, ent=ent, pairs=pairs, use_aer=use_aer_flag)
    Ktr = fidelity_kernel(SA, SA)
    svc = SVC(kernel="precomputed", probability=True, C=1.0, random_state=SEED).fit(Ktr, ytr_q)
    SB = sv_matrix(Xte_th, reps=reps, ent=ent, pairs=pairs, use_aer=use_aer_flag)
    Kte = fidelity_kernel(SB, SA)
    return svc.predict_proba(Kte)

# Experts (Terra/Aer path)
p_te_q1 = qsvc_probs(Xtr_th_q, ytr_q, Xte_th, reps=1, ent="linear")
p_te_q2 = qsvc_probs(Xtr_th_q, ytr_q, Xte_th, reps=2, ent="linear")

# -------------------------- QSVC baselines (ring_r1, rand_r1) --------------------------
p_qsvc_ring_r1 = qsvc_probs(Xtr_th_q, ytr_q, Xte_th, reps=1, ent="ring")

rng_np = np.random.default_rng(SEED+123)
rand_pairs = list(zip(rng_np.permutation(N_QUBITS)[:-1], rng_np.permutation(N_QUBITS)[1:]))
p_qsvc_rand_r1 = qsvc_probs(Xtr_th_q, ytr_q, Xte_th, reps=1, ent="random", pairs=rand_pairs)

# -------------------------- (Optional) qiskit-ml FidelityKernel path --------------------------
# If you want to try qiskit-ml kernels instead of Terra statevector kernels:
def qml_kernel_probs_or_none(Xtr_th_q, ytr_q, Xte_th, reps=1, entanglement="linear", shots=None):
    if not (HAS_QML and USE_QML):
        return None
    try:
        if shots and HAS_PRIMITIVES:
            # shot-based fidelity via primitives
            from qiskit.circuit.library import ZZFeatureMap
            fmap = ZZFeatureMap(feature_dimension=N_QUBITS, reps=reps, entanglement=entanglement)
            sampler = Sampler(options={"shots": shots})
            fidelity = ComputeUncompute(sampler)
            fid_kernel = FidelityQuantumKernel(feature_map=fmap, fidelity=fidelity)
            Ktr = fid_kernel.evaluate(Xtr_th_q, Xtr_th_q)
            svc = SVC(kernel="precomputed", probability=True, C=1.0, random_state=SEED).fit(Ktr, ytr_q)
            Kte = fid_kernel.evaluate(Xte_th, Xtr_th_q)
            return svc.predict_proba(Kte)
        else:
            # statevector style ML kernel (often needs Aer)
            from qiskit.circuit.library import ZZFeatureMap
            fmap = ZZFeatureMap(feature_dimension=N_QUBITS, reps=reps, entanglement=entanglement)
            if HAS_AER:
                backend = Aer.get_backend("statevector_simulator")
                qk = QuantumKernel(feature_map=fmap, quantum_instance=backend)
            else:
                # Some versions let quantum_instance=None; may still work. Catch and fallback.
                qk = QuantumKernel(feature_map=fmap)
            Ktr = qk.evaluate(Xtr_th_q, Xtr_th_q)
            svc = SVC(kernel="precomputed", probability=True, C=1.0, random_state=SEED).fit(Ktr, ytr_q)
            Kte = qk.evaluate(Xte_th, Xtr_th_q)
            return svc.predict_proba(Kte)
    except Exception as e:
        print(f"[warn] qiskit-ml kernel path failed ({e}); using Terra kernel instead.")
        return None

# Example (disabled by default):
# p_te_q1_qml = qml_kernel_probs_or_none(Xtr_th_q, ytr_q, Xte_th, reps=1, entanglement="linear", shots=None)

# -------------------------- Router fusion (PROPOSED) --------------------------
def router_features(p_class, p_q1, p_q2):
    maxp = np.max(p_class, axis=1, keepdims=True)
    return np.c_[p_class[:,1:2], maxp, p_q1[:,1:2], p_q2[:,1:2], np.abs(p_q1[:,1:2]-p_q2[:,1:2])]

F_ca = router_features(p_ca_c, qsvc_probs(Xtr_th_q, ytr_q, Xca_th, reps=1),
                       qsvc_probs(Xtr_th_q, ytr_q, Xca_th, reps=2))
router = LogisticRegression(max_iter=4000, random_state=SEED).fit(F_ca, y_ca)

final_prob = p_te_c.copy()
if route_mask.any():
    F_route = router_features(p_te_c[route_mask], p_te_q1[route_mask], p_te_q2[route_mask])
    p_route = router.predict_proba(F_route)[:,1]
    final_prob[route_mask,1] = p_route
    final_prob[route_mask,0] = 1 - p_route

# -------------------------- QKS baselines --------------------------
def expvals_z_all(statevector):
    probs = np.abs(statevector)**2
    n = int(math.log2(len(statevector)))
    idx = np.arange(len(statevector)); exps=[]
    for i in range(n):
        signs = 1 - 2*((idx >> i) & 1)   # +1 for |0>, -1 for |1>
        exps.append(np.sum(probs * signs))
    return np.array(exps)

class QKSFeaturizer:
    def __init__(self, n_qubits, sinks=8, reps=1, seed=0):
        self.nq=n_qubits; self.sinks=sinks; self.reps=reps
        self.rng=np.random.default_rng(seed)
        self.W=[self.rng.normal(0,1.0,size=(n_qubits,n_qubits)) for _ in range(sinks)]
        self.b=[self.rng.uniform(0,2*np.pi,size=(n_qubits,)) for _ in range(sinks)]
        self.pairs=[]
        for _ in range(sinks):
            perm=self.rng.permutation(n_qubits)
            self.pairs.append(list(zip(perm[:-1],perm[1:])))
    def transform(self, Xtheta):
        blocks=[]
        for s in range(self.sinks):
            W,b,pairs = self.W[s], self.b[s], self.pairs[s]
            feat=[]
            for x in Xtheta:
                angles=(W @ x + b) % (2*np.pi)
                sv=build_state(angles, reps=self.reps, ent="random", pairs=pairs)
                feat.append(expvals_z_all(sv))
            blocks.append(np.asarray(feat))
        return np.hstack(blocks)

# r=1
qks1 = QKSFeaturizer(N_QUBITS, sinks=QKS_SINKS, reps=QKS_R1, seed=SEED+7)
Xtr_k1 = qks1.transform(Xtr_th); Xte_k1 = qks1.transform(Xte_th)
qks_lr1 = LogisticRegression(max_iter=1000, random_state=SEED).fit(Xtr_k1, y_tr)
p_qks_lr_r1 = qks_lr1.predict_proba(Xte_k1)
# r=2
qks2 = QKSFeaturizer(N_QUBITS, sinks=QKS_SINKS, reps=QKS_R2, seed=SEED+9)
Xtr_k2 = qks2.transform(Xtr_th); Xte_k2 = qks2.transform(Xte_th)
qks_lr2 = LogisticRegression(max_iter=1000, random_state=SEED).fit(Xtr_k2, y_tr)
p_qks_lr_r2 = qks_lr2.predict_proba(Xte_k2)

# -------------------------- Classical baselines --------------------------
cl_lr_base = LogisticRegression(max_iter=1000, random_state=SEED).fit(Xtr_s, y_tr)
p_cl_lr = cl_lr_base.predict_proba(Xte_s)

cl_linsvm = LinearSVC(random_state=SEED).fit(Xtr_s, y_tr)
s_lin = cl_linsvm.decision_function(Xte_s); p_lin = 1/(1+np.exp(-s_lin)); p_cl_linsvm = np.c_[1-p_lin, p_lin]

cl_rbf = SVC(kernel="rbf", C=1.0, gamma="scale", probability=True, random_state=SEED).fit(Xtr_s, y_tr)
p_cl_rbf = cl_rbf.predict_proba(Xte_s)

# -------------------------- Collect models --------------------------
model_probs = {
    "Q-ProVe-Phish (PROPOSED)": final_prob,
    "QSVC_lin_r1": p_te_q1,
    "QSVC_lin_r2": p_te_q2,
    "QSVC_ring_r1": p_qsvc_ring_r1,
    "QSVC_rand_r1": p_qsvc_rand_r1,
    "QKS_LR_r1": p_qks_lr_r1,
    "QKS_LR_r2": p_qks_lr_r2,


}

# -------------------------- Leaderboard --------------------------
rows = []
for name, proba in model_probs.items():
    rows.append((name, all_metrics(y_te, proba)))
leader_df = pd.DataFrame({k: pd.Series(v) for k, v in rows}).T
ordered_cols = ['Accuracy','Precision','Recall','F1','ROC_AUC','PR_AUC','Log_Loss',
                'Balanced_Acc','Specificity_TNR','Cohen_Kappa','MCC','Brier_Score']
for c in ordered_cols:
    if c not in leader_df.columns: leader_df[c] = np.nan
leader_df = leader_df[ordered_cols].astype(float)
leader_sorted = leader_df.sort_values(by=["ROC_AUC","F1"], ascending=False)
csv_path = os.path.join(OUT_DIR, "leaderboard_all_metrics_UPDATED.csv")
leader_sorted.to_csv(csv_path)
print("\n=== Leaderboard (sorted by ROC_AUC, F1) — UPDATED ===")
print(leader_sorted.round(4))

# -------------------------- Dashboards --------------------------
def bar_panel(ax, vals, labels, title):
    ax.bar(range(len(vals)), vals)
    ax.set_xticks(range(len(vals)))
    ax.set_xticklabels(labels, rotation=60, ha='right', fontsize=8)
    ax.set_title(title)

# Evaluation dashboard: ROC, PR, and bars for ROC_AUC, F1, MCC, Balanced_Acc
fig = plt.figure(figsize=(16, 10))
gs = gridspec.GridSpec(2, 3, height_ratios=[1, 1.0], width_ratios=[1, 1, 1], wspace=0.25, hspace=0.25)

# ROC overlay
ax1 = fig.add_subplot(gs[0, 0])
for name, proba in model_probs.items():
    fpr, tpr, _ = roc_curve(y_te, clamp_proba(proba)[:,1])
    ax1.plot(fpr, tpr, lw=1.3, label=name)
ax1.plot([0,1],[0,1],'k--',lw=1)
ax1.set_title("ROC (all models)"); ax1.set_xlabel("FPR"); ax1.set_ylabel("TPR")
ax1.legend(fontsize=7, ncol=2)

# PR overlay
ax2 = fig.add_subplot(gs[0, 1])
for name, proba in model_probs.items():
    prec, rec, _ = precision_recall_curve(y_te, clamp_proba(proba)[:,1])
    ax2.plot(rec, prec, lw=1.3, label=name)
ax2.set_title("Precision–Recall (all models)"); ax2.set_xlabel("Recall"); ax2.set_ylabel("Precision")

# Bars
model_order = leader_sorted.index.tolist()
ax3 = fig.add_subplot(gs[0, 2]); bar_panel(ax3, leader_sorted["ROC_AUC"].values, model_order, "ROC_AUC (↑)")
ax4 = fig.add_subplot(gs[1, 0]); bar_panel(ax4, leader_sorted["F1"].values,       model_order, "F1 (↑)")
ax5 = fig.add_subplot(gs[1, 1]); bar_panel(ax5, leader_sorted["MCC"].values,      model_order, "MCC (↑)")
ax6 = fig.add_subplot(gs[1, 2]); bar_panel(ax6, leader_sorted["Balanced_Acc"].values, model_order, "Balanced Accuracy (↑)")

fig.suptitle("Q-ProVe-Phish — Evaluation Dashboard (UPDATED)", fontsize=14, y=1.02)
fig.tight_layout()
eval_path = os.path.join(OUT_DIR, "evaluation_dashboard_UPDATED.png")
fig.savefig(eval_path, dpi=150, bbox_inches='tight'); plt.close(fig)

# Diagnostics dashboard: Calibration, DET, Decision Curve
def plot_calibration_overlay(models_dict, y_true, ax):
    for name, proba in models_dict.items():
        prob = clamp_proba(proba)[:,1]
        frac_pos, mean_pred = calibration_curve(y_true, prob, n_bins=10, strategy="uniform")
        ax.plot(mean_pred, frac_pos, marker='o', ms=3, label=name)
    ax.plot([0,1],[0,1],'k--',lw=1)
    ax.set_title("Calibration (Reliability)"); ax.set_xlabel("Mean predicted probability"); ax.set_ylabel("Fraction of positives")

def plot_det_overlay(models_dict, y_true, ax):
    for name, proba in models_dict.items():
        fpr, tpr, _ = roc_curve(y_true, clamp_proba(proba)[:,1])
        ax.plot(fpr, 1-tpr, lw=1.2, label=name)
    ax.set_title("DET (False Alarm vs Miss)"); ax.set_xlabel("FPR"); ax.set_ylabel("FNR")

def plot_decision_curve(models_dict, y_true, ax):
    N = len(y_true); pts = np.linspace(0.01, 0.99, 50)
    for name, proba in models_dict.items():
        p = clamp_proba(proba)[:,1]; NB=[]
        for pt in pts:
            yhat = (p >= pt).astype(int)
            TP = np.sum((yhat==1) & (y_true==1)); FP = np.sum((yhat==1) & (y_true==0))
            NB.append((TP/N) - (FP/N)*(pt/(1-pt)))
        ax.plot(pts, NB, lw=1.2, label=name)
    ax.set_title("Decision Curve (Net Benefit)"); ax.set_xlabel("Threshold probability"); ax.set_ylabel("Net Benefit")

fig = plt.figure(figsize=(16, 9))
gs = gridspec.GridSpec(1, 3, width_ratios=[1,1,1], wspace=0.25)
axA = fig.add_subplot(gs[0,0]); axB = fig.add_subplot(gs[0,1]); axC = fig.add_subplot(gs[0,2])

# Use top-8 for readability
topk = min(8, len(leader_sorted))
top_list = leader_sorted.index[:topk].tolist()
top_probs = {k: model_probs[k] for k in top_list}

plot_calibration_overlay(top_probs, y_te, axA)
plot_det_overlay(top_probs, y_te, axB)
plot_decision_curve(top_probs, y_te, axC)
axA.legend(fontsize=7); axB.legend(fontsize=7); axC.legend(fontsize=7)

fig.suptitle("Diagnostics — Calibration • DET • Decision Curve (UPDATED)", fontsize=14, y=1.02)
fig.tight_layout()
diag_path = os.path.join(OUT_DIR, "diagnostics_dashboard_UPDATED.png")
fig.savefig(diag_path, dpi=150, bbox_inches='tight'); plt.close(fig)

# Policy dashboard: Gains, Lift, Threshold sweeps
def gains_curve(proba, y_true):
    prob = clamp_proba(proba)[:,1]
    order = np.argsort(-prob); y_sorted = y_true[order]
    cum_pos = np.cumsum(y_sorted); total_pos = max(1, y_true.sum())
    perc_samples = np.arange(1, len(y_true)+1)/len(y_true)
    gains = cum_pos/total_pos; lift = gains/np.clip(perc_samples, 1e-9, 1)
    return perc_samples, gains, lift

def threshold_sweeps(models_dict, y_true, metric="F1"):
    ths = np.linspace(0.05, 0.95, 37); curves = {}
    for name, proba in models_dict.items():
        p = clamp_proba(proba)[:,1]; vals=[]
        for t in ths:
            yhat = (p >= t).astype(int)
            if metric=="F1":
                vals.append(f1_score(y_true, yhat, zero_division=0))
            else:
                vals.append(matthews_corrcoef(y_true, yhat))
        curves[name]=(ths,np.array(vals))
    return curves

fig = plt.figure(figsize=(16, 10))
gs = gridspec.GridSpec(2, 2, wspace=0.25, hspace=0.25)
ax1 = fig.add_subplot(gs[0,0]); ax2 = fig.add_subplot(gs[0,1]); ax3 = fig.add_subplot(gs[1,0]); ax4 = fig.add_subplot(gs[1,1])

for name, proba in top_probs.items():
    x, g, L = gains_curve(proba, y_te)
    ax1.plot(x, g, lw=1.2, label=name)
    ax2.plot(x, L, lw=1.2, label=name)
ax1.plot([0,1],[0,1],'k--',lw=1)
ax1.set_title("Cumulative Gains"); ax1.set_xlabel("% of samples"); ax1.set_ylabel("% of positives")
ax2.set_title("Lift Curve"); ax2.set_xlabel("% of samples"); ax2.set_ylabel("Lift")

curves_f1  = threshold_sweeps(top_probs, y_te, metric="F1")
curves_mcc = threshold_sweeps(top_probs, y_te, metric="MCC")
for name,(ths,vals) in curves_f1.items():  ax3.plot(ths, vals, lw=1.2, label=name)
for name,(ths,vals) in curves_mcc.items(): ax4.plot(ths, vals, lw=1.2, label=name)
ax3.set_title("F1 vs Threshold"); ax3.set_xlabel("Threshold"); ax3.set_ylabel("F1")
ax4.set_title("MCC vs Threshold"); ax4.set_xlabel("Threshold"); ax4.set_ylabel("MCC")

ax1.legend(fontsize=7); ax2.legend(fontsize=7); ax3.legend(fontsize=7); ax4.legend(fontsize=7)
fig.suptitle("Policy — Gains • Lift • Threshold Sweeps (UPDATED)", fontsize=14, y=1.02)
fig.tight_layout()
pol_path = os.path.join(OUT_DIR, "policy_dashboard_UPDATED.png")
fig.savefig(pol_path, dpi=150, bbox_inches='tight'); plt.close(fig)

# Confusion matrices (single figure) + CSV
records = []; yhats = {}
for name, proba in model_probs.items():
    p = clamp_proba(proba)[:, 1]
    yhat = (p >= 0.5).astype(int)
    yhats[name] = yhat
    tn, fp, fn, tp = confusion_matrix(y_te, yhat, labels=[0, 1]).ravel()
    records.append({"Model": name, "TN": tn, "FP": fp, "FN": fn, "TP": tp})
cm_df = pd.DataFrame(records).set_index("Model")
cm_csv_path = os.path.join(OUT_DIR, "confusion_matrices_UPDATED.csv")
cm_df.to_csv(cm_csv_path)

import numpy as _np
n_models = len(model_probs); ncol = 4; nrow = int(math.ceil(n_models / ncol))
fig, axes = plt.subplots(nrow, ncol, figsize=(4.2 * ncol, 3.8 * nrow))
axes = _np.array(axes).reshape(nrow, ncol)
for ax in axes.flat: ax.axis("off")
for idx, (name, yhat) in enumerate(yhats.items()):
    r, c = divmod(idx, ncol); ax = axes[r, c]; ax.axis("on")
    cm = confusion_matrix(y_te, yhat, labels=[0, 1])
    cmn = cm.astype(float) / cm.sum(axis=1, keepdims=True); cmn = np.nan_to_num(cmn)
    im = ax.imshow(cmn, vmin=0, vmax=1)
    ax.set_title(name, fontsize=9)
    ax.set_xticks([0, 1]); ax.set_yticks([0, 1])
    ax.set_xticklabels(["Phish(0)", "Legit(1)"], rotation=30, ha="right", fontsize=8)
    ax.set_yticklabels(["Phish(0)", "Legit(1)"], fontsize=8)
    for i in range(2):
        for j in range(2):
            ax.text(j, i, f"{cm[i, j]}\n({cmn[i, j]:.2f})", ha="center", va="center", fontsize=8)
cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])
fig.colorbar(im, cax=cbar_ax, label="Normalized rate")
fig.suptitle("Confusion Matrices — counts (top) with normalized rates (bottom)", y=0.995)
fig.tight_layout(rect=[0, 0, 0.90, 0.97])
cm_fig_path = os.path.join(OUT_DIR, "confusion_matrices_UPDATED.png")
fig.savefig(cm_fig_path, dpi=150, bbox_inches="tight"); plt.close(fig)

print(f"\nArtifacts saved to: {OUT_DIR}/")
print(" -", csv_path)
print(" -", eval_path)
print(" -", diag_path)
print(" -", pol_path)
print(" -", cm_csv_path)
print(" -", cm_fig_path)
